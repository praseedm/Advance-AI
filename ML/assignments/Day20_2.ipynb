{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Develop a CNN model for solving the CIFAR10 dataset classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The CIFAR-10 data consists of 60,000 (32Ã—32) color images in 10 classes, with 6000 images per class.\n",
    "<img src=\"./CIFAR10.jpeg\" width=\"442\" />\n",
    "\n",
    "* Ref : https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    5000\n",
       "8    5000\n",
       "7    5000\n",
       "6    5000\n",
       "5    5000\n",
       "4    5000\n",
       "3    5000\n",
       "2    5000\n",
       "1    5000\n",
       "0    5000\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(y_train)\n",
    "d[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : Classify the given image into one of 10 classes\n",
    "* <h4>Class labels</h4>\n",
    "\n",
    "     * airplane : 0\n",
    "     * automobile : 1\n",
    "     * bird : 2\n",
    "     * cat : 3\n",
    "     * deer : 4\n",
    "     * dog : 5\n",
    "     * frog : 6\n",
    "     * horse : 7\n",
    "     * ship : 8\n",
    "     * truck : 9\n",
    "* <h4>Image</h4> \n",
    "        32 * 32 containing 3 values corresponding to each color component,\n",
    "        shape - (32,32,3)\n",
    "* <h4>There are 50,000 training images and 10,000 test images .</h4>  \n",
    "* <h4>Train Data</h4>\n",
    "        Images in 10 classes, with 5000 images per class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras import backend as bk\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Activation,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to saved model weights(as hdf5)\n",
    "resume_weights = \"./models/cifar10-cnn-best.hdf5\"\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reshape strategy according to backend\n",
    "if bk.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    # 3 x 32 x 32 [number_of_channels (colors) x height x weight]\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    # 32 x 32 x 3 [height x weight x number_of_channels (colors)]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "print x_train.shape  \n",
    "print input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print x_test.max()\n",
    "print x_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape, type, normalized, print\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print x_test.max()\n",
    "print x_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (50000, 32, 32, 3))\n",
      "(50000, 'train samples')\n",
      "(10000, 'test samples')\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,626,442\n",
      "Trainable params: 1,626,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "# Conv(32,3,3)[ReLU] -> Conv(64,3,3)[ReLU] -> MaxPool(2,2)[Dropout 0.25] ->FC(_, 128)[ReLU][Dropout 0.5] -> FC(128, 10)[Softmax]\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to TF graph \n",
    "import tensorflow as tf\n",
    "\n",
    "writer = tf.summary.FileWriter('./cifar10/tb1',bk.get_session().graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF graph\n",
    "<img src=\"./cifar10/cifar10_tfgraph.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model's weights from ./models/cifar10-cnn-best.hdf5\n"
     ]
    }
   ],
   "source": [
    "# If exists a best model, load its weights!\n",
    "if os.path.isfile(resume_weights):\n",
    "        print (\"Resumed model's weights from {}\".format(resume_weights))\n",
    "        # load weights\n",
    "        model.load_weights(resume_weights)\n",
    "\n",
    "# CEE, Adam\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint In the folder\n",
    "filepath = resume_weights\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 1.4026 - acc: 0.4923 - val_loss: 1.1539 - val_acc: 0.5988\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59880, saving model to ./models/cifar10-cnn-best.hdf5\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 365s 7ms/step - loss: 1.2564 - acc: 0.5515 - val_loss: 1.0795 - val_acc: 0.6138\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59880 to 0.61380, saving model to ./models/cifar10-cnn-best.hdf5\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 1.1716 - acc: 0.5852 - val_loss: 0.9831 - val_acc: 0.6557\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.61380 to 0.65570, saving model to ./models/cifar10-cnn-best.hdf5\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 246s 5ms/step - loss: 1.0956 - acc: 0.6109 - val_loss: 0.9603 - val_acc: 0.6628\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.65570 to 0.66280, saving model to ./models/cifar10-cnn-best.hdf5\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 1.0488 - acc: 0.6275 - val_loss: 0.9318 - val_acc: 0.6771\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.66280 to 0.67710, saving model to ./models/cifar10-cnn-best.hdf5\n",
      "('Test loss:', 0.9317553981781006)\n",
      "('Test accuracy:', 0.67710000000000004)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_train, y_train,\tbatch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=[checkpoint])\n",
    "\n",
    "# Eval\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
