{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Attempt at a model that finds out the most important words in a given document using\n",
    "i) term frequency\n",
    "ii) inverse document frequency.\n",
    "\n",
    "You may assume the document to be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Indian', 'banknote', 'demonetisation', 'On', '8', 'November', '2016', 'the', 'Government', 'of', 'India', 'announced', 'the', 'demonetisation', 'of', 'all', '500', 'and', '1000', 'banknotes', 'of', 'the', 'Mahatma', 'Gandhi', 'Series', 'Initially', 'the', 'move', 'received', 'support', 'from', 'several', 'bankers', 'as', 'well', 'as', 'from', 'some', 'international', 'commentators', 'The', 'move', 'was', 'also', 'criticised', 'as', 'poorly', 'planned', 'and', 'unfair', 'The', 'announcement', 'of', 'demonetisation', 'was', 'followed', 'by', 'prolonged', 'cash', 'shortages', 'in', 'the', 'weeks', 'that', 'followed', 'which', 'created', 'significant', 'disruption', 'throughout', 'the', 'economy'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open(\"input_file\",\"r\")\n",
    "data = TextBlob(fp.read())\n",
    "data.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words.count(Word('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "0.111111111111\n"
     ]
    }
   ],
   "source": [
    "# TF\n",
    "imp_w = data.words[0]\n",
    "imp_val = -1\n",
    "\n",
    "for word in data.words:\n",
    "    if(imp_val < ((float) (data.words.count(word)) / len(data.words))) :\n",
    "        imp_w = word\n",
    "        imp_val = (float) (data.words.count(word)) / len(data.words)\n",
    "        \n",
    "print imp_w \n",
    "print imp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data.sentences\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IDF\n",
    "\n",
    "def no_docs_cw(word):\n",
    "    global docs\n",
    "    c = 0\n",
    "    for doc in docs:\n",
    "        if(doc.words.count(word) > 0):\n",
    "            c += 1\n",
    "    return c\n",
    "    \n",
    "imp_w = data.words[0]\n",
    "imp_val = -1\n",
    "\n",
    "for doc in docs:\n",
    "    for word in doc.words:\n",
    "        \n",
    "        pval = (float)(len(docs))/no_docs_cw(word) \n",
    "        if(imp_val < pval) :\n",
    "            imp_w = word\n",
    "            imp_val = pval\n",
    "        \n",
    "print imp_w \n",
    "print imp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
